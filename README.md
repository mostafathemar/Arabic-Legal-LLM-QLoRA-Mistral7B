# ğŸ›ï¸ Ø§Ù„Ù…Ø³ØªØ´Ø§Ø± Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ Ø§Ù„Ø°ÙƒÙŠ | Saudi Legal AI Advisor

<div align="center">

**Ù†Ù…ÙˆØ°Ø¬ Ù„ØºÙˆÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… QLoRA Fine-Tuning**

**Specialized Arabic Legal Language Model for Saudi Law using QLoRA**

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![Transformers](https://img.shields.io/badge/ğŸ¤—-Transformers-yellow.svg)](https://huggingface.co/docs/transformers)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

Ø§Ù„Ù…Ø·ÙˆØ± | Developer: **Mostafa Ahmed El Sayed**

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0077B5?style=flat&logo=linkedin)](https://www.linkedin.com/in/mostafathemar/)
[![GitHub](https://img.shields.io/badge/GitHub-Follow-181717?style=flat&logo=github)](https://github.com/mostafathemar)

</div>

---

## ğŸ“‹ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙŠØ§Øª | Table of Contents

- [ğŸ¯ Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© | Overview](#-Ù†Ø¸Ø±Ø©-Ø¹Ø§Ù…Ø©--overview)
- [âœ¨ Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© | Key Features](#-Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª-Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©--key-features)
- [âš™ï¸ Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© | Tech Stack](#ï¸-Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª-Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©--tech-stack)
- [ğŸš€ Ø§Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ø³Ø±ÙŠØ¹ | Quick Start](#-Ø§Ù„Ø¨Ø¯Ø¡-Ø§Ù„Ø³Ø±ÙŠØ¹--quick-start)
- [ğŸ“ ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ | Training Details](#-ØªÙØ§ØµÙŠÙ„-Ø§Ù„ØªØ¯Ø±ÙŠØ¨--training-details)
- [âš™ï¸ Ø¶Ø¨Ø· Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª | Hyperparameter Tuning](#ï¸-Ø¶Ø¨Ø·-Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª--hyperparameter-tuning)
- [ğŸ“Š Ø§Ù„ØªÙ‚ÙŠÙŠÙ… | Evaluation](#-Ø§Ù„ØªÙ‚ÙŠÙŠÙ…--evaluation)
- [ğŸ’» Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… | Usage](#-Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…--usage)
- [ğŸ—ºï¸ Ø®Ø§Ø±Ø·Ø© Ø§Ù„Ø·Ø±ÙŠÙ‚ | Roadmap](#ï¸-Ø®Ø§Ø±Ø·Ø©-Ø§Ù„Ø·Ø±ÙŠÙ‚--roadmap)
- [ğŸ¤ Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø© | Contributing](#-Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø©--contributing)
- [ğŸ“„ Ø§Ù„ØªØ±Ø®ÙŠØµ | License](#-Ø§Ù„ØªØ±Ø®ÙŠØµ--license)
- [ğŸ“ Ø§Ù„ØªÙˆØ§ØµÙ„ | Contact](#-Ø§Ù„ØªÙˆØ§ØµÙ„--contact)
- [ğŸ™ Ø´ÙƒØ± ÙˆØªÙ‚Ø¯ÙŠØ± | Acknowledgments](#-Ø´ÙƒØ±-ÙˆØªÙ‚Ø¯ÙŠØ±--acknowledgments)

---

## ğŸ¯ Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© | Overview

<table>
<tr>
<td width="50%" dir="rtl">

### Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©

Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ÙŠÙ‚Ø¯Ù… **Ù…Ø³ØªØ´Ø§Ø± Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ** Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø­Ø¯ÙŠØ«Ø©. ØªÙ… Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø£Ø³Ø§Ø³ **Mistral-7B-Instruct-v0.2** ÙˆØªØ®ØµÙŠØµÙ‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ‚Ù†ÙŠØ© **QLoRA** Ù„ØªØ­Ù‚ÙŠÙ‚ Ø£Ø¯Ø§Ø¡ Ø¹Ø§Ù„Ù Ù…Ø¹ Ù…ÙˆØ§Ø±Ø¯ Ù…Ø­Ø¯ÙˆØ¯Ø©.

#### Ø§Ù„Ù…Ø´ÙƒÙ„Ø©

- Ù‚Ù„Ø© Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø°ÙƒÙŠØ© Ø§Ù„Ù…ØªØ®ØµØµØ© ÙÙŠ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
- ØµØ¹ÙˆØ¨Ø© Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø§Ø³ØªØ´Ø§Ø±Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©
- ØªÙƒÙ„ÙØ© Ø§Ù„Ø§Ø³ØªØ´Ø§Ø±Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠØ©

#### Ø§Ù„Ø­Ù„

Ù†Ù…ÙˆØ°Ø¬ Ù„ØºÙˆÙŠ Ù…ØªÙ‚Ø¯Ù… Ù‚Ø§Ø¯Ø± Ø¹Ù„Ù‰:

- ÙÙ‡Ù… Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©
- ØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù†Ø¸Ù…Ø© ÙˆØ§Ù„Ù„ÙˆØ§Ø¦Ø­
- Ø§Ù„ØªÙØ§Ø¹Ù„ Ø¨Ù„ØºØ© Ø¹Ø±Ø¨ÙŠØ© Ø·Ø¨ÙŠØ¹ÙŠØ© ÙˆÙˆØ§Ø¶Ø­Ø©

</td>
<td width="50%">

### English

This project presents a **Saudi Law specialized AI legal advisor** using cutting-edge AI techniques. Built on **Mistral-7B-Instruct-v0.2** and fine-tuned using **QLoRA** technology for high performance with limited resources.

#### The Problem

- Lack of specialized AI resources for Saudi law in Arabic
- Difficulty accessing accurate legal consultations
- High cost of traditional legal consultations

#### The Solution

An advanced language model capable of:

- Understanding complex Saudi legal terminology
- Providing accurate answers based on regulations and laws
- Interacting in natural and clear Arabic language

</td>
</tr>
</table>

---

## âœ¨ Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© | Key Features

<table>
<tr>
<td width="50%" dir="rtl">

### Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©

- âœ… **ØªØ®ØµØµ Ø¹Ù…ÙŠÙ‚**: ØªØ¯Ø±ÙŠØ¨ Ù…ØªØ®ØµØµ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† ÙˆØ§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©
- ğŸš€ **ÙƒÙØ§Ø¡Ø© Ø¹Ø§Ù„ÙŠØ©**: Ø§Ø³ØªØ®Ø¯Ø§Ù… QLoRA Ù„ØªØ¯Ø±ÙŠØ¨ Ø³Ø±ÙŠØ¹ Ø¹Ù„Ù‰ GPU Ù…Ø­Ø¯ÙˆØ¯Ø©
- ğŸ’¬ **ÙˆØ§Ø¬Ù‡Ø© ØªÙØ§Ø¹Ù„ÙŠØ©**: ØªØ·Ø¨ÙŠÙ‚ Gradio Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
- ğŸ¯ **Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©**: Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…ÙˆØ«ÙˆÙ‚Ø© Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
- ğŸ”§ **Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªÙˆØ³Ø¹**: Ø¨Ù†ÙŠØ© Ù…Ø±Ù†Ø© Ù„Ø¥Ø¶Ø§ÙØ© Ù…ÙŠØ²Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© (RAG, API)
- ğŸ“± **Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù…Ù†ØµØ§Øª**: ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ Colab, Local GPU, Cloud

</td>
<td width="50%">

### English

- âœ… **Deep Specialization**: Trained on Saudi laws and regulations
- ğŸš€ **High Efficiency**: QLoRA for fast training on limited GPU
- ğŸ’¬ **Interactive Interface**: Ready-to-use Gradio application
- ğŸ¯ **High Accuracy**: Reliable answers based on legal texts
- ğŸ”§ **Scalable**: Flexible architecture for new features (RAG, API)
- ğŸ“± **Multi-Platform**: Works on Colab, Local GPU, Cloud

</td>
</tr>
</table>

---

## âš™ï¸ Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© | Tech Stack

| Ø§Ù„ÙØ¦Ø© \| Category | Ø§Ù„Ø£Ø¯Ø§Ø© \| Tool | Ø§Ù„Ø¥ØµØ¯Ø§Ø± \| Version | Ø§Ù„ÙˆØµÙ \| Description |
|:---|:---|:---:|:---|
| **Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ**<br>Base Model | Mistral-7B-Instruct-v0.2 | v0.2 | Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØªÙˆØ­ Ø§Ù„Ù…ØµØ¯Ø± Ù…ØªÙ‚Ø¯Ù…<br>Advanced open-source model |
| **Ø§Ù„ØªØ®ØµÙŠØµ**<br>Fine-Tuning | QLoRA + PEFT | Latest | ØªØ¯Ø±ÙŠØ¨ ÙØ¹Ø§Ù„ Ù…Ø¹ 4-bit quantization<br>Efficient training with 4-bit quantization |
| **Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**<br>Data Processing | Pandas, Datasets | Latest | ØªÙ†Ø¸ÙŠÙ ÙˆØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª<br>Data cleaning and preparation |
| **Ø§Ù„ØªÙ‚ÙŠÙŠÙ…**<br>Evaluation | ROUGE, BLEU, Cosine Similarity | - | Ù‚ÙŠØ§Ø³ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª<br>Measuring answer quality |
| **Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©**<br>Interface | Gradio | 4.0+ | ÙˆØ§Ø¬Ù‡Ø© Ù…Ø³ØªØ®Ø¯Ù… ØªÙØ§Ø¹Ù„ÙŠØ©<br>Interactive user interface |
| **Ø§Ù„ØªØ®Ø²ÙŠÙ†**<br>Storage | Google Drive, HuggingFace Hub | - | Ø­ÙØ¸ ÙˆØ§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬<br>Model storage and retrieval |

---

## ğŸš€ Ø§Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ø³Ø±ÙŠØ¹ | Quick Start

### Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© | Prerequisites
```bash
# Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… | System Requirements
- Python 3.10+
- CUDA 12.1+ (Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ GPU | For GPU training)
- 16GB+ RAM
- Google Colab (Ù…Ø¬Ø§Ù†ÙŠ Ù…Ø¹ T4 GPU | Free with T4 GPU) Ø£Ùˆ | or
- Local GPU (RTX 3060 12GB Ø£Ùˆ Ø£Ø¹Ù„Ù‰ | or higher)
```

### 1ï¸âƒ£ Ø§Ù„ØªØ«Ø¨ÙŠØª | Installation
```python
# ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© | Install core libraries
!pip install -q unsloth[cu121] bitsandbytes accelerate
!pip install -q peft trl datasets pandas gradio transformers

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ«Ø¨ÙŠØª | Verify installation
import torch
print(f"âœ… PyTorch: {torch.__version__}")
print(f"âœ… CUDA Available: {torch.cuda.is_available()}")
print(f"âœ… GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}")
```

### 2ï¸âƒ£ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª | Data Preparation
```python
# Ù‡ÙŠÙƒÙ„ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª | Data file structure
# train_data.jsonl
{
  "instruction": "Ù…Ø§ Ù‡ÙŠ Ø¹Ù‚ÙˆØ¨Ø© Ø§Ù„ØªØ²ÙˆÙŠØ± ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØŸ",
  "input": "",
  "output": "ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØŒ Ø¹Ù‚ÙˆØ¨Ø© Ø§Ù„ØªØ²ÙˆÙŠØ± Ù‡ÙŠ..."
}
```

### 3ï¸âƒ£ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ | Training
```python
# Ø§ÙØªØ­ Notebook Ø§Ù„ØªØ¯Ø±ÙŠØ¨ | Open Training Notebook
# 01_FineTuning_Saudi_Law_Expert.ipynb

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ | Load base model
from unsloth import FastLanguageModel

model, tokenizer = FastLanguageModel.from_pretrained(
    model_name="mistralai/Mistral-7B-Instruct-v0.2",
    max_seq_length=2048,
    dtype=None,
    load_in_4bit=True,
)

# ØªØ·Ø¨ÙŠÙ‚ QLoRA | Apply QLoRA
model = FastLanguageModel.get_peft_model(
    model,
    r=16,
    lora_alpha=32,
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],
    lora_dropout=0.05,
    bias="none",
)

# Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ | Start training
trainer.train()
```

### 4ï¸âƒ£ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… | Usage
```python
# Ø§ÙØªØ­ Notebook Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… | Open Inference Notebook
# 02_Saudi_Law_AI_Chat.ipynb

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ÙØ¯Ø±Ø¨ | Load trained model
model = FastLanguageModel.from_pretrained(
    model_name="path/to/lora_adapter",
    max_seq_length=2048,
)

# Ø¥Ø·Ù„Ø§Ù‚ ÙˆØ§Ø¬Ù‡Ø© Gradio | Launch Gradio interface
import gradio as gr

demo = gr.Interface(
    fn=generate_response,
    inputs=gr.Textbox(label="Ø³Ø¤Ø§Ù„Ùƒ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ | Your Legal Question"),
    outputs=gr.Textbox(label="Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© | Answer"),
    title="ğŸ›ï¸ Ø§Ù„Ù…Ø³ØªØ´Ø§Ø± Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ"
)

demo.launch()
```

---

## ğŸ“ ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ | Training Details

### Ù„Ù…Ø§Ø°Ø§ QLoRAØŸ | Why QLoRA?

<table>
<tr>
<td width="50%" dir="rtl">

### Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©

**QLoRA** ØªÙ‚Ù†ÙŠØ© Ø«ÙˆØ±ÙŠØ© ØªØ¬Ù…Ø¹ Ø¨ÙŠÙ†:

- **Quantization**: ØªÙ‚Ù„ÙŠÙ„ Ø¯Ù‚Ø© Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø¥Ù„Ù‰ 4-bit
- **LoRA**: ØªØ¯Ø±ÙŠØ¨ Ø·Ø¨Ù‚Ø§Øª ØµØºÙŠØ±Ø© ÙÙ‚Ø· (Adapters)

#### Ø§Ù„ÙÙˆØ§Ø¦Ø¯

- ğŸ’¾ **ØªÙˆÙÙŠØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø©**: ØªÙ‚Ù„ÙŠÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… VRAM Ø¨Ù†Ø³Ø¨Ø© 75%
- âš¡ **Ø³Ø±Ø¹Ø© Ø£Ø¹Ù„Ù‰**: ØªØ¯Ø±ÙŠØ¨ Ø£Ø³Ø±Ø¹ 3-4x
- ğŸ’° **ØªÙƒÙ„ÙØ© Ø£Ù‚Ù„**: ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ GPU Ù…Ø¬Ø§Ù†ÙŠØ© (Colab T4)
- ğŸ¯ **Ù†ÙØ³ Ø§Ù„Ø¬ÙˆØ¯Ø©**: Ø£Ø¯Ø§Ø¡ Ù…Ù…Ø§Ø«Ù„ Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ÙƒØ§Ù…Ù„

</td>
<td width="50%">

### English

**QLoRA** is a revolutionary technique combining:

- **Quantization**: Reducing weight precision to 4-bit
- **LoRA**: Training only small layers (Adapters)

#### Benefits

- ğŸ’¾ **Memory Efficient**: 75% less VRAM usage
- âš¡ **Faster**: 3-4x faster training
- ğŸ’° **Cost-Effective**: Works on free GPU (Colab T4)
- ğŸ¯ **Same Quality**: Performance comparable to full training

</td>
</tr>
</table>

### Ù…Ø¹Ù…Ø§Ø±ÙŠØ© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ | Model Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Mistral-7B-Instruct-v0.2 (Base)      â”‚
â”‚        (Frozen - 4bit Quantized)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   LoRA Adapters   â”‚
        â”‚   (Trainable)     â”‚
        â”‚   - r=16          â”‚
        â”‚   - alpha=32      â”‚
        â”‚   - dropout=0.05  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Legal Saudi Model â”‚
        â”‚   (Fine-tuned)    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ Ø¶Ø¨Ø· Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª | Hyperparameter Tuning

| Ø§Ù„Ù…Ø¹Ø§Ù…Ù„ \| Parameter | Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡Ø§<br>Recommended | Ø§Ù„Ù†Ø·Ø§Ù‚ \| Range | Ø§Ù„ØªØ£Ø«ÙŠØ± \| Impact |
|:---|:---:|:---:|:---|
| `lora_r` | 16 | 8-64 | Ø±ØªØ¨Ø© Ù…ØµÙÙˆÙØ© LoRA - Ø²ÙŠØ§Ø¯ØªÙ‡Ø§ ØªØ­Ø³Ù† Ø§Ù„ØªØ¹Ù„Ù…<br>LoRA rank - higher improves learning |
| `lora_alpha` | 32 | 16-128 | Ù‚ÙˆØ© Ø§Ù„Ø¯Ù…Ø¬ - Ø¹Ø§Ø¯Ø© Ø¶Ø¹Ù r<br>Scaling factor - usually 2Ã—r |
| `max_seq_length` | 2048 | 512-4096 | Ø·ÙˆÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚ - Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø·ÙˆÙŠÙ„Ø©<br>Context length - for long texts |
| `num_train_epochs` | 3 | 1-10 | Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ù‚Ø¨ - Ø§Ø­Ø°Ø± Ù…Ù† Overfitting<br>Training epochs - watch for overfitting |
| `learning_rate` | 2e-4 | 1e-5 - 5e-4 | Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù… - Ø§Ù„Ø£Ù‡Ù… Ù„Ù„Ø¬ÙˆØ¯Ø©<br>Learning rate - critical for quality |
| `per_device_batch_size` | 4 | 1-16 | Ø­Ø¬Ù… Ø§Ù„Ø¯ÙØ¹Ø© - Ø­Ø³Ø¨ VRAM<br>Batch size - depends on VRAM |
| `gradient_accumulation` | 4 | 1-32 | Ù„Ù…Ø­Ø§ÙƒØ§Ø© batch Ø£ÙƒØ¨Ø±<br>To simulate larger batches |

### Ù…Ø«Ø§Ù„ Ø§Ù„ØªÙƒÙˆÙŠÙ† Ø§Ù„Ø£Ù…Ø«Ù„ | Optimal Configuration Example
```python
training_arguments = TrainingArguments(
    output_dir="./saudi_law_model",
    num_train_epochs=3,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,
    learning_rate=2e-4,
    fp16=True,
    logging_steps=10,
    save_strategy="epoch",
    warmup_steps=100,
)
```

---

## ğŸ“Š Ø§Ù„ØªÙ‚ÙŠÙŠÙ… | Evaluation

### Ø·Ø±Ù‚ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… | Evaluation Methods

<table>
<tr>
<td width="50%" dir="rtl">

#### 1. Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¢Ù„ÙŠ | Automatic Evaluation

- **ROUGE Score**: Ù‚ÙŠØ§Ø³ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ù…Ø¹ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©
- **BLEU Score**: ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„ØªØ±Ø¬Ù…Ø© ÙˆØ§Ù„ØµÙŠØ§ØºØ©
- **Cosine Similarity**: ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø¯Ù„Ø§Ù„Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª

#### 2. Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ÙŠØ¯ÙˆÙŠ | Manual Evaluation

- Ø¯Ù‚Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
- ÙˆØ¶ÙˆØ­ Ø§Ù„ØµÙŠØ§ØºØ©
- Ø§Ù„Ø´Ù…ÙˆÙ„ÙŠØ© ÙˆØ§Ù„ØªÙØµÙŠÙ„

</td>
<td width="50%">

#### 1. Automatic Evaluation

- **ROUGE Score**: Similarity with reference answers
- **BLEU Score**: Translation and phrasing quality
- **Cosine Similarity**: Semantic similarity

#### 2. Manual Evaluation

- Legal information accuracy
- Clarity of expression
- Comprehensiveness and detail

</td>
</tr>
</table>

### Ù…Ø«Ø§Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ | Sample Results
```
Test Set Performance:
â”œâ”€â”€ ROUGE-L: 0.82
â”œâ”€â”€ BLEU Score: 0.76
â”œâ”€â”€ Accuracy: 89%
â””â”€â”€ Response Time: <2s
```

---

## ğŸ’» Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… | Usage

### Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¹Ø¨Ø± Gradio | Using Gradio Interface
```python
import gradio as gr

def ask_legal_question(question):
    prompt = f"""### Ø§Ù„Ø³Ø¤Ø§Ù„:
{question}

### Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:"""
    
    response = model.generate(prompt, max_length=512)
    return response

interface = gr.Interface(
    fn=ask_legal_question,
    inputs=gr.Textbox(
        label="Ø§Ø·Ø±Ø­ Ø³Ø¤Ø§Ù„Ùƒ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ",
        placeholder="Ù…Ø«Ø§Ù„: Ù…Ø§ Ù‡ÙŠ Ø´Ø±ÙˆØ· Ø§Ù„Ø²ÙˆØ§Ø¬ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØŸ"
    ),
    outputs=gr.Textbox(label="Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©"),
    title="ğŸ›ï¸ Ø§Ù„Ù…Ø³ØªØ´Ø§Ø± Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ",
    description="Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ"
)

interface.launch(share=True)
```

### Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¹Ø¨Ø± Python API | Using Python API
```python
from transformers import AutoModelForCausalLM, AutoTokenizer

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ | Load model
model = AutoModelForCausalLM.from_pretrained("path/to/model")
tokenizer = AutoTokenizer.from_pretrained("path/to/model")

# Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… | Query
question = "Ù…Ø§ Ù‡ÙŠ Ø¹Ù‚ÙˆØ¨Ø© Ø§Ù„Ø³Ø±Ù‚Ø© ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØŸ"
inputs = tokenizer(question, return_tensors="pt")
outputs = model.generate(**inputs, max_length=200)
answer = tokenizer.decode(outputs[0])

print(answer)
```

---

## ğŸ—ºï¸ Ø®Ø§Ø±Ø·Ø© Ø§Ù„Ø·Ø±ÙŠÙ‚ | Roadmap

<table>
<tr>
<td width="50%" dir="rtl">

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø© (Q1 2025)

- [ ] **Ø¯Ù…Ø¬ RAG**: Ø¥Ø¶Ø§ÙØ© Ù‚Ø§Ø¹Ø¯Ø© Ù…Ø¹Ø±ÙØ© Ù…ÙˆØ³Ø¹Ø©
- [ ] **API RESTful**: ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬ÙŠØ© Ù„Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª
- [ ] **ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ù„Ù†Øµ**: Ø§Ø³ØªØ´Ø§Ø±Ø§Øª ØµÙˆØªÙŠØ©
- [ ] **Ù†Ù…ÙˆØ°Ø¬ Ø£ÙƒØ¨Ø±**: ØªØ±Ù‚ÙŠØ© Ø¥Ù„Ù‰ Mistral-13B

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© (Q2-Q3 2025)

- [ ] **Multi-turn Dialog**: Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø£Ø¯ÙˆØ§Ø±
- [ ] **Document Analysis**: ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
- [ ] **Mobile App**: ØªØ·Ø¨ÙŠÙ‚ Ù‡Ø§ØªÙ Ù…Ø­Ù…ÙˆÙ„
- [ ] **Ø¯Ø¹Ù… Ø¯ÙˆÙ„ Ø®Ù„ÙŠØ¬ÙŠØ© Ø£Ø®Ø±Ù‰**: ØªÙˆØ³ÙŠØ¹ Ø§Ù„ØªØºØ·ÙŠØ©

</td>
<td width="50%">

### Next Phase (Q1 2025)

- [ ] **RAG Integration**: Extended knowledge base
- [ ] **RESTful API**: Application programming interface
- [ ] **Speech-to-Text**: Voice consultations
- [ ] **Larger Model**: Upgrade to Mistral-13B

### Advanced Phase (Q2-Q3 2025)

- [ ] **Multi-turn Dialog**: Conversation context
- [ ] **Document Analysis**: Legal document processing
- [ ] **Mobile App**: Mobile application
- [ ] **GCC Coverage**: Expand to other Gulf countries

</td>
</tr>
</table>

---

## ğŸ¤ Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø© | Contributing

<table>
<tr>
<td width="50%" dir="rtl">

### Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©

Ù†Ø±Ø­Ø¨ Ø¨Ù…Ø³Ø§Ù‡Ù…Ø§ØªÙƒÙ…! ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø© Ø¹Ø¨Ø±:

1. **Fork** Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
2. Ø¥Ù†Ø´Ø§Ø¡ **Branch** Ø¬Ø¯ÙŠØ¯ (`git checkout -b feature/AmazingFeature`)
3. **Commit** Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª (`git commit -m 'Add some AmazingFeature'`)
4. **Push** Ù„Ù„Ù€ Branch (`git push origin feature/AmazingFeature`)
5. ÙØªØ­ **Pull Request**

#### Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø©

- Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨ Ø¬Ø¯ÙŠØ¯Ø©
- ØªØ­Ø³ÙŠÙ† Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
- ØªØ±Ø¬Ù…Ø© Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
- ÙƒØªØ§Ø¨Ø© Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚
- Ø§Ø®ØªØ¨Ø§Ø± ÙˆØ¥ØµÙ„Ø§Ø­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡

</td>
<td width="50%">

### English

We welcome your contributions! You can contribute by:

1. **Fork** the project
2. Create a new **Branch** (`git checkout -b feature/AmazingFeature`)
3. **Commit** your changes (`git commit -m 'Add some AmazingFeature'`)
4. **Push** to the Branch (`git push origin feature/AmazingFeature`)
5. Open a **Pull Request**

#### Contribution Areas

- Add new training data
- Improve model accuracy
- Translate interface
- Write documentation
- Test and fix bugs

</td>
</tr>
</table>

---

## ğŸ“„ Ø§Ù„ØªØ±Ø®ÙŠØµ | License
```
MIT License

Copyright (c) 2025 Mostafa Ahmed El Sayed

ÙŠÙØ³Ù…Ø­ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØªØ¹Ø¯ÙŠÙ„ ÙˆØªÙˆØ²ÙŠØ¹ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¨Ø­Ø±ÙŠØ©
This project is free to use, modify, and distribute
```

---

## ğŸ“ Ø§Ù„ØªÙˆØ§ØµÙ„ | Contact

<div align="center">

**Mostafa Ahmed El Sayed**

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/mostafathemar/)
[![GitHub](https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/mostafathemar)

ğŸ“§ **Email**: [mostafathemar@gmail.com]

ğŸŒ **Website**: [https://www.linkedin.com/in/mostafathemar/]

</div>

---

## ğŸ™ Ø´ÙƒØ± ÙˆØªÙ‚Ø¯ÙŠØ± | Acknowledgments

<table>
<tr>
<td width="50%" dir="rtl">

### Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©

- **Mistral AI** - Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ø§Ù„Ù…ÙØªÙˆØ­ Ø§Ù„Ù…ØµØ¯Ø±
- **Hugging Face** - Ù„Ù…ÙƒØªØ¨Ø§Øª Transformers Ùˆ PEFT
- **Unsloth** - Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª QLoRA
- **Google Colab** - Ù„ØªÙˆÙÙŠØ± Ù…ÙˆØ§Ø±Ø¯ GPU Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠØ©
- **Ø§Ù„Ù…Ø¬ØªÙ…Ø¹ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ** - Ù„Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ø¥Ù„Ù‡Ø§Ù…

</td>
<td width="50%">

### English

- **Mistral AI** - For the open-source base model
- **Hugging Face** - For Transformers and PEFT libraries
- **Unsloth** - For QLoRA optimizations
- **Google Colab** - For providing free GPU resources
- **Arabic AI Community** - For support and inspiration

</td>
</tr>
</table>

---

<div align="center">

### â­ Ø¥Ø°Ø§ Ø£Ø¹Ø¬Ø¨Ùƒ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ØŒ Ù„Ø§ ØªÙ†Ø³Ù Ø¥Ø¶Ø§ÙØ© Ù†Ø¬Ù…Ø©!
### â­ If you like this project, don't forget to star it!

**ØµÙÙ†Ø¹ Ø¨Ù€ â¤ï¸ ÙÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© | Made with â¤ï¸ in Saudi Arabia**

</div>
